# Model arguments
model_name_or_path: Gensyn/Qwen2.5-0.5B-Instruct
model_revision: main
torch_dtype: float32               # Используем float32 для работы на CPU
attn_implementation: "eager"       # Использование стандартной реализации внимания
bf16: false
tf32: false
output_dir: runs/gsm8k/cpu/Qwen2.5-0.5B-Instruct

# Dataset arguments
dataset_id_or_path: 'openai/gsm8k'

# Training arguments
max_steps: 500                     # Было 100 — увеличено для более длительной тренировки
per_device_train_batch_size: 32    # Увеличиваем размер батча для загрузки CPU
gradient_accumulation_steps: 1     # Накопление градиентов за один шаг
gradient_checkpointing: true       # Использование градиентного чекпоинтинга
gradient_checkpointing_kwargs:
  use_reentrant: false             # Отключено использование reentrant
learning_rate: 1.0e-6              # Повышенная скорость обучения
lr_scheduler_type: cosine
warmup_ratio: 0.1                  # Увеличено время "разогрева"

# GRPO specific parameters
beta: 0.001
max_prompt_length: 256
max_completion_length: 1024       # Увеличено для генерации более длинных текстов
num_generations: 8                # Увеличено количество генераций на итерацию
use_vllm: false

# Logging arguments
logging_strategy: steps
logging_steps: 2
report_to:
- tensorboard
save_strategy: "steps"
save_steps: 20
seed: 42

# Script arguments
max_rounds: 10000

# Оптимизация для CPU
num_workers: 16                    # Увеличено количество потоков
pin_memory: true                   # Для более эффективного использования памяти
